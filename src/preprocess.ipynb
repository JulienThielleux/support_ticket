{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"../.env/config.json\", \"r\") as f:\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "PROJECT_ID = CONFIG[\"project_id\"]\n",
    "BUCKET_NAME = CONFIG[\"bucket_name\"]\n",
    "MODEL_NAME = CONFIG[\"model_name\"]\n",
    "LOCATION = CONFIG[\"location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#authentication to GCP\n",
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../.env/service-account.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48549, 9)\n"
     ]
    }
   ],
   "source": [
    "#get the file from the bucket\n",
    "import io\n",
    "\n",
    "def read_from_bucket(filename):\n",
    "    try:\n",
    "        client = storage.Client(project=PROJECT_ID)\n",
    "        bucket = client.bucket(BUCKET_NAME)\n",
    "        blob = bucket.blob(filename)\n",
    "        file_content = blob.download_as_bytes()\n",
    "        return pd.read_csv(io.BytesIO(file_content))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file from bucket: {e}\")\n",
    "        raise\n",
    "\n",
    "df_raw = read_from_bucket(\"all_tickets.csv\")\n",
    "\n",
    "print(df_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47837, 1)\n",
      "                                                Text\n",
      "1  title:connection with icon;body:icon dear plea...\n",
      "2  title:work experience user;body:work experienc...\n",
      "3  title:requesting for meeting;body:requesting m...\n",
      "4  title:reset passwords for external accounts;bo...\n",
      "5  title:mail;body:verification warning hi has go...\n"
     ]
    }
   ],
   "source": [
    "#preprocessing\n",
    "#we keep only the columns we need\n",
    "df = df_raw[[\"title\",\"body\"]]\n",
    "\n",
    "#dropping the missing values\n",
    "df = df.dropna()\n",
    "\n",
    "#concatenating the title and body\n",
    "df[\"Text\"] = \"title:\" + df[\"title\"] + \";body:\" + df[\"body\"]\n",
    "df = df.drop(columns=[\"title\",\"body\"])\n",
    "print(df.shape)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14488931 characters in the dataset\n",
      "2.8977862 dollars expected to embed this dataset\n"
     ]
    }
   ],
   "source": [
    "#we calculate the number of characters in the dataset and estimate a price for embedding\n",
    "total_char = df[\"Text\"].apply(len).sum()\n",
    "print(f\"{total_char} characters in the dataset\")\n",
    "print(f\"{total_char * 0.0002 / 1000} dollars expected to embed this dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text embedding functions\n",
    "from google.api_core import retry\n",
    "import google.generativeai as genai\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "#function to get embeddings for a batch of texts\n",
    "@retry.Retry(timeout=300.0)\n",
    "def embed_fn_batch(texts: list[str]) -> list[list[float]]:\n",
    "    response = genai.embed_content(\n",
    "        model=f\"models/{MODEL_NAME}\", content=texts, task_type=\"clustering\"\n",
    "    )\n",
    "\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "#function to process the texts in batches\n",
    "def process_in_batches(texts: list[str], batch_size: int = 200):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing batches\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        embeddings.extend(embed_fn_batch(batch))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 240/240 [15:02<00:00,  3.76s/it]\n"
     ]
    }
   ],
   "source": [
    "#embedding\n",
    "texts = df[\"Text\"].tolist()\n",
    "df[\"Embeddings\"] = process_in_batches(texts, batch_size=200)\n",
    "\n",
    "#saving the embeddings\n",
    "df.to_csv(\"../embeddings/all_tickets_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Text\":\"id\",\"Embeddings\":\"embedding\"})\n",
    "\n",
    "#saving to json\n",
    "json_data = df.to_json(orient=\"records\")\n",
    "with open(\"../embeddings/all_tickets_embeddings.json\", \"w\") as f:\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending the embeddings to a bucket\n",
    "df.to_json(f\"gs://{BUCKET_NAME}/all_tickets_embeddings.json\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/802291245749/locations/us-central1/indexes/1491425950426988544/operations/3493933939423182848\n",
      "MatchingEngineIndex created. Resource name: projects/802291245749/locations/us-central1/indexes/1491425950426988544\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/802291245749/locations/us-central1/indexes/1491425950426988544')\n",
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/802291245749/locations/us-central1/indexEndpoints/3788631196292874240/operations/5832005833470246912\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/802291245749/locations/us-central1/indexEndpoints/3788631196292874240\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/802291245749/locations/us-central1/indexEndpoints/3788631196292874240')\n",
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/802291245749/locations/us-central1/indexEndpoints/3788631196292874240\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/802291245749/locations/us-central1/indexEndpoints/3788631196292874240/operations/1927807169005092864\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/802291245749/locations/us-central1/indexEndpoints/3788631196292874240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint.MatchingEngineIndexEndpoint object at 0x0000019E98ECF9D0> \n",
       "resource name: projects/802291245749/locations/us-central1/indexEndpoints/3788631196292874240"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sending to a vector database\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "DEPLOYED_INDEX_ID = \"support_tickets_index_deployed\"\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "#creating the index\n",
    "my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=\"support-tickets-index\",\n",
    "    contents_delta_uri=f\"gs://{BUCKET_NAME}/all_tickets_embeddings.json\",\n",
    "    dimensions=768,\n",
    "    approximate_neighbors_count=5,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    ")\n",
    "\n",
    "#creating IndexEndpoint\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=\"support-tickets-index-endpoint\",\n",
    "    public_endpoint_enabled=True,\n",
    ")\n",
    "\n",
    "#deploying the Index to the Index Endpoint\n",
    "my_index_endpoint.deploy_index(index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
